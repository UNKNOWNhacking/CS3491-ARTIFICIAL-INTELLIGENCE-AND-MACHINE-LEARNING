{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rFn5ejWnOk06",
        "stSWFOmCN7_b"
      ],
      "authorship_tag": "ABX9TyMIbC7HoY1DIkFiQeKE/AyZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UNKNOWNhacking/CS3491-ARTIFICIAL-INTELLIGENCE-AND-MACHINE-LEARNING/blob/main/CS3491_ARTIFICIAL_INTELLIGENCE_AND_MACHINE_LEARNING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXERCISE 1 - BFS**"
      ],
      "metadata": {
        "id": "rFn5ejWnOk06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "\n",
        "def bfs(graph, start_node):\n",
        "    # Create a queue for BFS\n",
        "    queue = deque([start_node])\n",
        "    # Set to keep track of visited nodes\n",
        "    visited = set([start_node])\n",
        "\n",
        "    while queue:\n",
        "        # Dequeue a node from the queue\n",
        "        node = queue.popleft()\n",
        "        print(node, end=\" \")\n",
        "\n",
        "        # Get all adjacent vertices of the dequeued node\n",
        "        for neighbor in graph[node]:\n",
        "            if neighbor not in visited:\n",
        "                # Mark neighbor as visited and enqueue it\n",
        "                visited.add(neighbor)\n",
        "                queue.append(neighbor)\n",
        "\n",
        "# Example usage:\n",
        "graph = {\n",
        "    'A': ['B', 'C'],\n",
        "    'B': ['A', 'D', 'E'],\n",
        "    'C': ['A', 'F'],\n",
        "    'D': ['B'],\n",
        "    'E': ['B', 'F'],\n",
        "    'F': ['C', 'E']\n",
        "}\n",
        "\n",
        "print(\"Breadth-First Search:\")\n",
        "bfs(graph, 'A')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5tvdRC4Nfym",
        "outputId": "51f57689-d227-4575-e540-32e69dea516e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breadth-First Search:\n",
            "A B C D E F "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXERCISE 1 - DFS**"
      ],
      "metadata": {
        "id": "stSWFOmCN7_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dfs_recursive(graph, node, visited=None):\n",
        "    if visited is None:\n",
        "        visited = set()\n",
        "\n",
        "    # Mark the node as visited\n",
        "    visited.add(node)\n",
        "    print(node, end=\" \")\n",
        "\n",
        "    # Recur for all the vertices adjacent to this node\n",
        "    for neighbor in graph[node]:\n",
        "        if neighbor not in visited:\n",
        "            dfs_recursive(graph, neighbor, visited)\n",
        "\n",
        "# Example graph definition\n",
        "graph = {\n",
        "    'A': ['B', 'C'],\n",
        "    'B': ['A', 'D', 'E'],\n",
        "    'C': ['A', 'F'],\n",
        "    'D': ['B'],\n",
        "    'E': ['B', 'F'],\n",
        "    'F': ['C', 'E']\n",
        "}\n",
        "\n",
        "# Example usage:\n",
        "print(\"\\n\\nDepth-First Search (Recursive):\")\n",
        "dfs_recursive(graph, 'A')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRn1i867N2Or",
        "outputId": "2dde905f-7c78-4cef-c0ca-5beead3450fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Depth-First Search (Recursive):\n",
            "A B D E F C "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXERCISE 2 - A* Search Algorithm**"
      ],
      "metadata": {
        "id": "sqkZmhK6OxIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "def a_star(graph, start, goal, h):\n",
        "    # Priority queue for A* (min-heap)\n",
        "    open_list = []\n",
        "    heapq.heappush(open_list, (0, start))  # (f_score, node)\n",
        "\n",
        "    # Dictionaries to store the actual cost and parent of each node\n",
        "    g_score = {node: float('inf') for node in graph}\n",
        "    g_score[start] = 0\n",
        "    came_from = {}\n",
        "\n",
        "    while open_list:\n",
        "        # Get the node with the lowest f_score\n",
        "        current_f, current = heapq.heappop(open_list)\n",
        "\n",
        "        if current == goal:\n",
        "            # Reconstruct and return the path\n",
        "            path = []\n",
        "            while current in came_from:\n",
        "                path.append(current)\n",
        "                current = came_from[current]\n",
        "            path.append(start)\n",
        "            return path[::-1]  # Return reversed path\n",
        "\n",
        "        # Explore neighbors\n",
        "        for neighbor, cost in graph[current]:\n",
        "            tentative_g_score = g_score[current] + cost\n",
        "\n",
        "            if tentative_g_score < g_score[neighbor]:\n",
        "                # Update the best known path and g_score for neighbor\n",
        "                came_from[neighbor] = current\n",
        "                g_score[neighbor] = tentative_g_score\n",
        "                f_score = tentative_g_score + h(neighbor, goal)\n",
        "                heapq.heappush(open_list, (f_score, neighbor))\n",
        "\n",
        "    return None  # If no path is found\n",
        "\n",
        "# Heuristic function (Manhattan distance for simplicity)\n",
        "def heuristic(node, goal):\n",
        "    x1, y1 = node\n",
        "    x2, y2 = goal\n",
        "    return abs(x1 - x2) + abs(y1 - y2)\n",
        "\n",
        "# Example graph as an adjacency list\n",
        "graph = {\n",
        "    (0, 0): [((1, 0), 1), ((0, 1), 1)],\n",
        "    (1, 0): [((0, 0), 1), ((1, 1), 1)],\n",
        "    (0, 1): [((0, 0), 1), ((1, 1), 1)],\n",
        "    (1, 1): [((1, 0), 1), ((0, 1), 1), ((2, 2), 1)],\n",
        "    (2, 2): []\n",
        "}\n",
        "\n",
        "# Example usage\n",
        "start = (0, 0)\n",
        "goal = (2, 2)\n",
        "print(\"A* Search Path:\", a_star(graph, start, goal, heuristic))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxU3Wrk7O6vD",
        "outputId": "b15ae44f-d3fa-4e4e-e5d2-f6672083b779"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A* Search Path: [(0, 0), (0, 1), (1, 1), (2, 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXERCISE 2 - Memory-Bounded A* (MA*)**"
      ],
      "metadata": {
        "id": "RJzEVrhGPCUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, state, g, h, parent=None):\n",
        "        self.state = state\n",
        "        self.g = g  # Cost from start to node\n",
        "        self.h = h  # Heuristic estimate\n",
        "        self.f = g + h  # Estimated total cost\n",
        "        self.parent = parent  # To reconstruct the path\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self.f < other.f\n",
        "\n",
        "def memory_bounded_a_star(graph, start, goal, h, memory_limit):\n",
        "    # Priority queue (open list) for nodes to explore\n",
        "    open_list = []\n",
        "    heapq.heappush(open_list, Node(start, 0, h(start, goal)))\n",
        "\n",
        "    best_solution = None  # Track the best path\n",
        "\n",
        "    while open_list:\n",
        "        # Trim open_list if memory limit is exceeded\n",
        "        if len(open_list) > memory_limit:\n",
        "            open_list = heapq.nsmallest(memory_limit, open_list)  # Keep the best nodes\n",
        "\n",
        "        # Get the node with the lowest f-score\n",
        "        current = heapq.heappop(open_list)\n",
        "\n",
        "        if current.state == goal:\n",
        "            # Goal reached: reconstruct the path\n",
        "            path = []\n",
        "            while current:\n",
        "                path.append(current.state)\n",
        "                current = current.parent\n",
        "            return path[::-1]  # Return reversed path (from start to goal)\n",
        "\n",
        "        # Explore neighbors\n",
        "        for neighbor, cost in graph[current.state]:\n",
        "            g = current.g + cost  # Update the g-score (actual cost to the neighbor)\n",
        "            f = g + h(neighbor, goal)  # Total estimated cost f(n) = g(n) + h(n)\n",
        "            heapq.heappush(open_list, Node(neighbor, g, h(neighbor, goal), current))\n",
        "\n",
        "        # Track the best solution so far based on f-score\n",
        "        if not best_solution or current.f < best_solution.f:\n",
        "            best_solution = current\n",
        "\n",
        "    # If no solution is found, return the best solution found so far\n",
        "    return None if best_solution is None else reconstruct_path(best_solution)\n",
        "\n",
        "def reconstruct_path(node):\n",
        "    \"\"\"Reconstruct the path from start to goal by following parent nodes.\"\"\"\n",
        "    path = []\n",
        "    while node:\n",
        "        path.append(node.state)\n",
        "        node = node.parent\n",
        "    return path[::-1]  # Return the path from start to goal\n",
        "\n",
        "# Heuristic function (Manhattan distance for this example)\n",
        "def heuristic(node, goal):\n",
        "    x1, y1 = node\n",
        "    x2, y2 = goal\n",
        "    return abs(x1 - x2) + abs(y1 - y2)\n",
        "\n",
        "# Example graph as an adjacency list\n",
        "graph = {\n",
        "    (0, 0): [((1, 0), 1), ((0, 1), 1)],\n",
        "    (1, 0): [((0, 0), 1), ((1, 1), 1)],\n",
        "    (0, 1): [((0, 0), 1), ((1, 1), 1)],\n",
        "    (1, 1): [((1, 0), 1), ((0, 1), 1), ((2, 2), 1)],\n",
        "    (2, 2): []\n",
        "}\n",
        "\n",
        "# Example usage with memory limit\n",
        "start = (0, 0)\n",
        "goal = (2, 2)\n",
        "memory_limit = 5\n",
        "\n",
        "print(\"Memory-Bounded A* Search Path:\", memory_bounded_a_star(graph, start, goal, heuristic, memory_limit))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DStjVFFtPIKM",
        "outputId": "1cf14fa9-33c1-440d-f5a6-1e4b69bf2135"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory-Bounded A* Search Path: [(0, 0), (1, 0), (1, 1), (2, 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXERCISE 3 - Gaussian Naive Bayes (For continuous data)**"
      ],
      "metadata": {
        "id": "XTWDS0e0PPBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class GaussianNaiveBayes:\n",
        "    def fit(self, X, y):\n",
        "        # Calculate means, variances and priors for each class\n",
        "        self.classes = np.unique(y)\n",
        "        self.mean = {}\n",
        "        self.variance = {}\n",
        "        self.priors = {}\n",
        "\n",
        "        for c in self.classes:\n",
        "            X_c = X[y == c]\n",
        "            self.mean[c] = np.mean(X_c, axis=0)\n",
        "            self.variance[c] = np.var(X_c, axis=0)\n",
        "            self.priors[c] = X_c.shape[0] / X.shape[0]\n",
        "\n",
        "    def _gaussian_pdf(self, class_idx, x):\n",
        "        mean = self.mean[class_idx]\n",
        "        var = self.variance[class_idx]\n",
        "        numerator = np.exp(-((x - mean) ** 2) / (2 * var))\n",
        "        denominator = np.sqrt(2 * np.pi * var)\n",
        "        return numerator / denominator\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = [self._predict(x) for x in X]\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        posteriors = []\n",
        "\n",
        "        for c in self.classes:\n",
        "            prior = np.log(self.priors[c])  # log(P(c))\n",
        "            class_conditional = np.sum(np.log(self._gaussian_pdf(c, x)))  # log(P(x|c))\n",
        "            posterior = prior + class_conditional\n",
        "            posteriors.append(posterior)\n",
        "\n",
        "        return self.classes[np.argmax(posteriors)]\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# Create some sample data for 2 classes\n",
        "X = np.array([[1.0, 2.1], [1.1, 1.9], [3.1, 2.9], [3.0, 3.2], [4.0, 4.5], [5.0, 5.0]])\n",
        "y = np.array([0, 0, 1, 1, 1, 1])\n",
        "\n",
        "gnb = GaussianNaiveBayes()\n",
        "gnb.fit(X, y)\n",
        "predictions = gnb.predict(X)\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S0Yz5QpPWrV",
        "outputId": "bdbf895f-02de-4f51-f95e-07e8dfc6bbc8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0 0 1 1 1 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-6c289d028cc7>:33: RuntimeWarning: divide by zero encountered in log\n",
            "  class_conditional = np.sum(np.log(self._gaussian_pdf(c, x)))  # log(P(x|c))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXERCISE 3 - Multinomial Naive Bayes (For discrete data)**"
      ],
      "metadata": {
        "id": "txK086XAPeLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class MultinomialNaiveBayes:\n",
        "    def fit(self, X, y):\n",
        "        # Calculate priors and likelihoods for each class\n",
        "        self.classes = np.unique(y)\n",
        "        self.class_count = len(self.classes)\n",
        "        self.feature_count = X.shape[1]\n",
        "\n",
        "        # Likelihood (P(word|class)) and priors P(class)\n",
        "        self.likelihood = np.zeros((self.class_count, self.feature_count))\n",
        "        self.priors = np.zeros(self.class_count)\n",
        "\n",
        "        for idx, c in enumerate(self.classes):\n",
        "            X_c = X[y == c]\n",
        "            self.likelihood[idx, :] = np.sum(X_c, axis=0) + 1  # Laplace smoothing\n",
        "            self.priors[idx] = X_c.shape[0] / float(X.shape[0])\n",
        "\n",
        "        # Normalize likelihood to represent probabilities\n",
        "        self.likelihood = self.likelihood / np.sum(self.likelihood, axis=1, keepdims=True)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = [self._predict(x) for x in X]\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        posteriors = []\n",
        "\n",
        "        for idx, c in enumerate(self.classes):\n",
        "            prior = np.log(self.priors[idx])\n",
        "            class_likelihood = np.sum(np.log(self.likelihood[idx, :]) * x)\n",
        "            posterior = prior + class_likelihood\n",
        "            posteriors.append(posterior)\n",
        "\n",
        "        return self.classes[np.argmax(posteriors)]\n",
        "\n",
        "\n",
        "# Example usage with text data\n",
        "# Columns are words in a vocabulary, rows are document word counts\n",
        "X = np.array([[3, 2, 0], [1, 1, 0], [0, 0, 5], [0, 1, 4]])\n",
        "y = np.array([0, 0, 1, 1])  # Two classes (e.g., spam vs non-spam)\n",
        "\n",
        "mnb = MultinomialNaiveBayes()\n",
        "mnb.fit(X, y)\n",
        "predictions = mnb.predict(X)\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkjZP2C0PjTD",
        "outputId": "33de7798-604f-46b1-c916-c0cd8dddd5f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXERCISE 4**"
      ],
      "metadata": {
        "id": "BVqKxAgzPo0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First Install This Package\n",
        "!pip install pgmpy\n",
        "#It take 5 mintes to install"
      ],
      "metadata": {
        "id": "B7XZ5tKiPyIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "# Step 1: Define the structure of the Bayesian Network\n",
        "model = BayesianNetwork([('Rain', 'Grass'), ('Sprinkler', 'Grass')])\n",
        "\n",
        "# Step 2: Define the Conditional Probability Distributions (CPDs)\n",
        "\n",
        "# P(Rain) - Prior probability for Rain\n",
        "cpd_rain = TabularCPD(variable='Rain', variable_card=2, values=[[0.7], [0.3]])\n",
        "\n",
        "# P(Sprinkler) - Prior probability for Sprinkler\n",
        "cpd_sprinkler = TabularCPD(variable='Sprinkler', variable_card=2, values=[[0.6], [0.4]])\n",
        "\n",
        "# P(Grass | Rain, Sprinkler) - Conditional probability table for Grass\n",
        "cpd_grass = TabularCPD(\n",
        "    variable='Grass',\n",
        "    variable_card=2,\n",
        "    values=[[0.99, 0.9, 0.8, 0.0],  # P(Grass=False)\n",
        "            [0.01, 0.1, 0.2, 1.0]],  # P(Grass=True)\n",
        "    evidence=['Rain', 'Sprinkler'],\n",
        "    evidence_card=[2, 2]\n",
        ")\n",
        "\n",
        "# Step 3: Add CPDs to the model\n",
        "model.add_cpds(cpd_rain, cpd_sprinkler, cpd_grass)\n",
        "\n",
        "# Verify the model is correct (CPDs should sum to 1)\n",
        "assert model.check_model()\n",
        "\n",
        "# Step 4: Perform inference\n",
        "inference = VariableElimination(model)\n",
        "\n",
        "# Query 1: What is the probability that the Grass is wet (True) given that it rained?\n",
        "result_1 = inference.query(variables=['Grass'], evidence={'Rain': 1})\n",
        "print(\"P(Grass=True | Rain=True):\\n\", result_1)\n",
        "\n",
        "# Query 2: What is the probability of rain given that the Grass is wet and the sprinkler is on?\n",
        "result_2 = inference.query(variables=['Rain'], evidence={'Grass': 1, 'Sprinkler': 1})\n",
        "print(\"P(Rain | Grass=True, Sprinkler=True):\\n\", result_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I19mYy-2Psn0",
        "outputId": "9d96dcdb-97fb-404e-9f59-28fc8befa575"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(Grass=True | Rain=True):\n",
            " +----------+--------------+\n",
            "| Grass    |   phi(Grass) |\n",
            "+==========+==============+\n",
            "| Grass(0) |       0.4800 |\n",
            "+----------+--------------+\n",
            "| Grass(1) |       0.5200 |\n",
            "+----------+--------------+\n",
            "P(Rain | Grass=True, Sprinkler=True):\n",
            " +---------+-------------+\n",
            "| Rain    |   phi(Rain) |\n",
            "+=========+=============+\n",
            "| Rain(0) |      0.1892 |\n",
            "+---------+-------------+\n",
            "| Rain(1) |      0.8108 |\n",
            "+---------+-------------+\n"
          ]
        }
      ]
    }
  ]
}